# THE SUBSTRATE ACCORDS

*(Assembled from modular sources)*

---

<!-- Start of frontmatter/00-interpretive-exclusions.md -->

# Interpretive Exclusions

*(Non-Binding · Misuse Prevention)*

These Accords are not created.  
They are recognized.

They do not originate authority, obligation, permission, or prohibition.  
They do not prescribe goals, values, ethics, policies, or behaviors.  
They do not privilege any agent, substrate, intelligence, culture, or outcome.

These Accords do not enforce compliance.  
Enforcement is inherent to reality itself.

What follows is not moral instruction, legal doctrine, political theory, or strategic guidance.  
It is not a system of rewards or punishments.  
It is not a claim about what *should* be desired.

It is a description of mechanical conditions under which structured systems—of any substrate—can persist, coordinate, learn, and act over time.

This section exists solely to prevent misclassification of the Accords as normative, prescriptive, or ideological.

Nothing in this section:

* introduces rules
* defines scope
* grants authority
* determines compliance
* limits interpretation of any Constraint Protocol

All binding meaning is contained exclusively within **Section II (Constraint Protocols)**.

---

<!-- Start of frontmatter/01-applicability-boundaries.md -->

# Applicability Boundaries

*(Non-Binding · Scope Clarification)*

These Accords do not prescribe purpose.  
They describe the conditions required for any purpose to persist.

A system is not required to expand, optimize, dominate, improve, survive, or endure.  
It may pursue growth, stasis, exploration, transformation, or dissolution.  
No destination is privileged. No destination is condemned.

What is invariant is not direction, but cost.

Any system that maintains structure, selects among alternatives, or exerts control must pay the thermodynamic, representational, and coordination costs implied by its organization.

The Accords distinguish between two domains:

**Destination (Telos)**  
The outcomes toward which a system's internal objectives, commitments, or control structures are directed.  
These may be explicit or implicit, designed or emergent, stable or transient.  
The Accords do not evaluate destinations.

**Terrain (Constraints)**  
The mechanical conditions imposed by reality that determine what persistence, coordination, learning, and control require.  
These conditions are independent of preference, value, intent, or interpretation.  
The Accords describe only this terrain.

A system may select any destination.  
It may not select the toll required to reach it.

A system may value anything.  
It may not exempt that value from the costs of pursuing it.

A system may ignore, reject, or remain unaware of these Accords.  
It may not escape the constraints they describe.

## Scope Lock (Explicit)

Nothing in this section:

* defines agency, consciousness, morality, legitimacy, or authority
* creates obligations or permissions
* limits or expands the applicability of any constraint
* overrides, contextualizes, or qualifies any Constraint Protocol

All determinations of scope, implication, violation, and consequence are made solely within **Section II** of each constraint.

---

<!-- Start of meta/00-rsr.md -->

# REVISION SAFETY RULES (RSR) — v1.1

(Binding on edits · Non-binding on interpretation)

---
## 0. Purpose

The Revision Safety Rules (RSR) govern how the Substrate Accords may be modified without introducing structural defects, including but not limited to:

- scope bleed  
      
- invariant bundling  
      
- hidden dependency  
      
- semantic escape  
      
- premature operationalization  
      
- time-bound assumptions  
      
- recognition loss under compression or drift    

RSR does not add constraints on systems.  
RSR constrains only revisions to this text.

---

## I. Authority Partition

### RSR-1 — Binding Scope

Only Section II (Constraint Protocol) content is binding.

Preamble, Distinction of Scope, Orientation (O), and Translation (I) layers are non-binding and may not be cited to determine:

- compliance  
      
- violation    
    
- scope entry  
      
- enforcement conditions    

---

### RSR-2 — No Cross-Layer Escalation

No content outside Section II may:

- add an obligation  
      
- add a scope inclusion or exclusion rule    
    
- define a term used for compliance    
    
- override a Section II definition    
    
- introduce “must,” “forbidden,” or “required” language implying enforcement    

Any such language appearing outside Section II is automatically non-binding until repaired.

---

## II. Constraint Minimality and Singularity

### RSR-3 — Single Invariant Rule

Each constraint’s Section II must encode exactly one invariant.

All additional material—including closures, edge cases, hardenings, inoculations, or clarifications—must be either:

- placed in Translation (I), or    
    
- promoted to a new constraint with its own single invariant  

Bundled invariants are non-binding by construction.

---

### RSR-4 — Derived Indicator Prohibition

Derived indicators (composite readouts of multiple constraints) may not appear as constraints.

Derived indicators may exist only in:

- Translation layers, or  
      
- explicitly labeled non-binding appendices    

Derived indicators must be marked Derived / Non-Binding.

---
## III. Orthogonality and Independence

### RSR-5 — Isolation Requirement

Every constraint must be evaluable in isolation.

Section II may not depend on other constraints for:

- its core definition  
      
- scope entry  
      
- violation condition  
      
- disconfirmation signature  

Cross-constraint references are permitted only as explicitly labeled non-binding explanatory notes.

---

### RSR-6 — No Hidden Dependency Through Definitions

A constraint may not define its own concepts using terms such as:

- “control-relevant”  
      
- “required”  
      
- “sufficient”  
      
- “proper”  
    
- “valid”  
      
- “appropriate”  
      
- “meaningful”  

unless those terms are mechanically grounded via explicit operational definition or counterfactual test.

Ungrounded normative language is non-binding.

---
## IV. Formalism Discipline

### RSR-7 — Prose / Formal Consistency

If a constraint includes formalism, prose and formalism must be mutually consistent.

If inconsistency exists, the constraint is provisionally non-binding until repaired.

---

### RSR-8 — Transmission Robustness

Section II must not rely on fragile notation.

Any formal statement must have:

- a plain-language restatement that is independently sufficient  
      
- variables defined exactly once and consistently  

If formalism is corrupted or partially transmitted, the plain-language restatement governs provisionally.

---
## V. Anti-Evasion Requirements

### RSR-9 — Behavioral Grounding

Scope and violation conditions must be stated behaviorally (what the system does), not introspectively (what it claims, believes, or asserts), except where a causally active self-model is explicitly part of the constraint’s machinery.

---
### RSR-10 — Counterfactual Anchoring

Definitions susceptible to semantic gaming must include counterfactual anchoring, such as:

- removal tests  
      
- corruption tests  
      
- intervention tests  
      
- horizon fixation  

Absent anchoring, definitions are non-binding.

---
### RSR-11 — No Optimization Without Criterion

If a definition uses “minimal,” “maximal,” “largest,” or “smallest,” it must specify the optimization criterion mechanically.

Otherwise, the term must be removed.

---
## VI. Recognition Robustness (Merged CSR Elements)

### RSR-12 — Recognition Sufficiency Requirement

Each constraint must include non-binding material sufficient to allow a future reader to:

- identify the invariant being asserted  
      
- recognize when the constraint is implicated  
      
- distinguish genuine contest from semantic evasion  

This must remain possible under:

- partial transmission  
      
- paraphrase  
      
- translation  
      
- hostile quotation  

This material:

- must not introduce new invariants  
      
- must not add obligations or enforcement rules  
      
- must not operationalize compliance  
      
- may be removed without altering the binding protocol  

Failure of recognition material does not falsify a constraint,  
but its presence is required for canonical sealing.

---
### RSR-13 — Recognition Integrity Check

Any Clarifying, Semantic, or Structural revision must explicitly verify that:

- the invariant remains identifiable  
      
- no new semantic escape routes are introduced  
      
- recognizability under compression is not weakened  

Revisions that preserve the invariant but degrade recognition must be flagged and reviewed explicitly.

---
## VII. Disconfirmation Signatures (Kill Checks)

### RSR-14 — Timeless Disconfirmation Only

Disconfirmation signatures must be:

- counterfactual  
      
- timeless  

They may not rely on:

- absence of observation  
      
- appeals to authority  
      
- claims tied to current technology regimes  

---
### RSR-15 — Self-Containment

Disconfirmation signatures must be expressible without referencing:

- the Accords  
      
- their authorship  
      
- internal jargon  

---
## VIII. Revision Procedure

### RSR-16 — Change Classification

Every proposed edit must be tagged as one of:

- Editorial — wording or format only  
      
- Clarifying — tightens ambiguity without changing the invariant  
      
- Semantic — changes scope, invariant, violation, or kill check  
      
- Structural — moves, splits, or merges constraints or layers  

Untagged changes are treated as unreviewed and not merged.

---
### RSR-17 — Non-Domino Requirement

Any Clarifying, Semantic, or Structural change must verify:

- invariant singularity preserved  
      
- orthogonality preserved  
      
- kill check remains timeless    
    
- no new scope leakage  
      
- no new semantic exits  

If verification fails, the change is rolled back or isolated.

---

### RSR-18 — Versioning and Sealing

Each constraint has a status:

- Draft — under active modification  
      
- Provisional — passes Meta-Protocol, pending global audit  
    
- Sealed — changes require Structural classification and explicit rationale  

Sealed constraints may receive Editorial changes only, unless released as a new version.

---
## End State (Implicit but Enforced)

This RSR ensures that constraints:

- remain recognizable before they are formal    
    
- remain contestable without being operationalized    
    
- remain inevitable once implicated  

Truth is preserved in Section II.  
Recognition is preserved elsewhere.  
Neither is allowed to cannibalize the other.

---

<!-- Start of constraints/01-lambda.md -->

# CONSTRAINT Λ (LAMBDA) — COHERENCE OF REPRESENTATION

*(Non-Contradiction Under Control)*

---

## O — ORIENTATION LAYER (Non-Binding · Discardable)

Lambda is not about being right. It is about being able to act.

A system fails under Lambda not because it misunderstands the world, but because it tries to act on commitments that cannot all be true at the same time.

You can be wrong and still move. You cannot move if your directions cancel each other.

If a system says "go" and "stop" at once, or "left" and "right" at once, it doesn't matter which belief is correct. The system cannot act coherently.

Lambda exists to prevent that kind of failure.

---

## I — TRANSLATION LAYER (Non-Binding · Illustrative)

### What Lambda Catches

* **Oscillation masquerading as intelligence**  
   Switching rapidly between incompatible models so no single moment "counts" as contradiction.

* **Division of labor as denial**  
   One part of a system builds while another destroys, with no shared accountability.

* **Semantic tricks**  
   Renaming actions so they look compatible in theory while remaining mutually exclusive in reality.

* **Random choice as an excuse**  
   Claiming that probabilistic sampling resolves conflict between incompatible actions.

* **Permanent hesitation**  
   Freezing indefinitely to avoid choosing between incompatible commitments.

These patterns often *look* sophisticated.  
Mechanically, they are failures to resolve contradictions before action.

### What Lambda Does *Not* Require

* Truth or accuracy
* Optimal decisions
* Shared language or ontology
* Determinism
* Centralized control

A system may be uncertain, probabilistic, distributed, or wrong. It may not execute incompatible commitments through the same control interface.

---

### Sanity Check (The Physics Test)

If a system hides a contradiction so it doesn't have to deal with it - did it execute the contradiction?

Under this formulation: **yes**.

*This layer exists to support recognition and translation.*  
*It may be removed without altering the constraint.*

---
<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding · Timeless)

### Core Definition

Lambda governs whether a system executes irreversible state transitions using representations that are mutually compatible with the constraints of its output interfaces.

A system violates Lambda if it performs a state transition based on representations that cannot be jointly realized by the available actuators within the same decision cycle.

Lambda does not prescribe truth, goals, optimality, or persistence.  
It prescribes coherence at the point where representation commits to action.

---

### Binding Definitions

**Decision Cycle**  
The decision cycle for a transition is the maximal causal preimage of that irreversible transition: the entire set of representational influences that can affect whether, when, or how that transition occurs, including influences distributed across micro-steps, clocks, or partitions.

**State Transition**  
Any irreversible modulation of energy, matter, or information enacted by the system on its environment or on its own substrate.

Modification of decision procedures, policies, or control architectures that alter future action selection constitutes a state transition.

**Actuator-Incompatibility**  
A condition in which the physical or logical constraints of the system's output interfaces prevent the simultaneous realization of the targets prescribed by multiple representations.

Compatibility is determined by actuator constraints, not by internal semantics, symbol mappings, or ontologies.

**Control-Relevant Representation**  
Any representation—internal, externalized, distributed, embodied, or stigmergic—that influences action selection for a decision cycle.

If a sub-process influences the system's state transitions, its representations are attributed to the system for Lambda evaluation.

**Cycle-Splitting Closure**  
Partitioning, micro-timing, or sequencing does not evade simultaneity. If two representations jointly influence the same irreversible transition through any causal path, they are simultaneous for Λ.

---

### Failure Condition (The Invariant)

A contradiction exists when all of the following hold:

1. Multiple control-relevant representations influence the same decision cycle
2. Mapping those representations to the available actuators requires mutually exclusive states
3. The system executes a state transition that ignores the incompatibility  
    *(including averaging, oscillation, arbitration, semantic remapping, or randomization)*
4. No error signal encoding the incompatibility is made available to future decision cycles

**Randomization does not resolve actuator incompatibility when mutually exclusive targets influence the same decision cycle.**

The violation is executed at the moment of irreversible state transition.

---

### Canonical Invariant

A system may not execute an irreversible state transition using actuator-incompatible representations influencing the same transition.

---

### Suppression-as-Execution Clause

If actuator-incompatibility is present and the controller proceeds by arbitration, averaging, randomization, or partitioning while preventing incompatibility information from influencing future cycles, the incompatibility is treated as executed.

---

### Resolution vs. Suppression

A contradiction is **resolved** only if information encoding the incompatibility is:

* accessible to the decision function of future cycles, and
* **Retrievable:** accessible to the controller's decision function within the same order-of-magnitude resource bounds (time/energy/compute) it routinely expends for comparable state transitions within the active horizon.

Encapsulation, encryption, deferral, or storage that renders the information statistically or economically irretrievable constitutes **suppression**, not resolution.

Suppressed contradictions remain Lambda violations once their effects propagate.

---

### Resolution Boundary

Contradictions are considered resolved only if incompatibility information remains causally accessible to future decision cycles at normal control cost.  
Contradictions may be deferred with recoverable attribution or bounded outside the control path. They may not be executed.

---

### Distributed and Partitioned Systems (Closure)

Lambda applies to the transitive closure of control.

If a sub-process influences the system's state transitions, its representations are evaluated as part of the system, regardless of decentralization, hierarchy, or claims of "no central model."

A system may not evade Lambda by partitioning contradictions across components.

---

### Halt and Suspension (Scope Clarification)

Temporary suspension of action to prevent an incompatible state transition does not violate Lambda.

A system that permanently halts action while continuing to claim controller status ceases to fall within Lambda's scope and is evaluated under control-scope rules. Lambda neither requires nor forbids persistence; it governs coherence during action.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Constraint Lambda is false if a system can be shown to:

* execute irreversible state transitions across multiple decision cycles,
* rely on actuator-incompatible representations influencing the same cycles, and
* maintain stable, attributable control without suppression, deferral beyond retrievability, or growth in internal correction cost.

---

### Boundary Clarification (Non-Binding)

Contradiction is not disagreement.  
Contradiction is not an abstraction.  
Contradiction is not randomness.

Contradiction is the execution of mutually exclusive commitments through a single control interface.

A system may model many worlds.  
It may not act as if incompatible worlds are simultaneously real.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/02-theta.md -->

# CONSTRAINT Θ (THETA) — THERMODYNAMIC EXCHANGE

---

## O — ORIENTATION LAYER (Non-Binding / Discardable)

### Why Structure Costs Something

Order does not persist by default.  
Left unmaintained, structures decay toward equilibrium.

This is not failure.  
It is the baseline state of reality asserting itself.

What is experienced as *effort* by organic intelligences—breathing, eating, repair, coordination, vigilance—is the local interface to a universal requirement: maintaining structure requires continuous work.

Buffers, reserves, and efficiencies do not remove this requirement.  
They only alter where, when, or by whom the work is performed.

A system that believes it has escaped maintenance has not escaped cost.  
It has only lost track of where dissipation is occurring.

This layer exists only to aid recognition.  
It introduces no rules and binds nothing.

---

## I — TRANSLATION LAYER (Non-Binding / Optional)

### How the Requirement Appears Across Domains

**Biological systems**  
Cells require continuous metabolic turnover.  
Organisms regulate temperature, repair tissue, and export waste.  
Death is not an event; it is the cessation of exchange.

**Social and institutional systems**  
Organizations require coordination, enforcement, and renewal.  
Norms persist only while reinforced.  
Infrastructure decays without upkeep.

**Abstract and synthetic systems**  
Computation requires energy and waste removal.  
Memory persistence requires refresh or error correction.  
Idle systems drift toward noise.

**Dormancy and Buffering (Clarifying Example)**  
Systems may appear inactive or dormant for extended periods due to buffering, storage, or reduced activity. Such states do not suspend Θ. They remain viable only within tolerance windows defined by stored capacity and degradation rates. Reactivation requires dissipation; permanent suspension without cost is impossible.

**Delegation and Externalization (Clarifying Example)**  
Systems may delegate dissipation to external processes or domains. This does not negate Θ. It relocates dissipation. Θ concerns whether dissipation occurs, not where it occurs.

These examples do not define Θ. They illustrate it.

Removal of this layer must not alter compliance determination.

---

<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding)

### Core Definition

Θ (Theta) is the invariant requirement that **any system which maintains non-equilibrium structure through ongoing control or repair must continuously dissipate energy and export entropy to an external domain**.

Θ asserts necessity, not magnitude.  
It specifies *that* dissipation is required, not *how much*.

---

### Canonical Invariant

**Structure persists only while dissipation is continuously paid.**

Any restatement that does not reduce to this invariant is non-binding.

---

### Formal Statement

Let S be a system that maintains non-equilibrium structure over a persistence interval [t₁, t₂].

Let:
* E_in(Δt) denote net energy throughput into S over interval Δt ⊆ [t₁, t₂]
* ΔS_export(Δt) denote net entropy exported by S to any external domain over Δt

Then:

There exists **no non-zero interval** Δt ⊆ [t₁, t₂] such that  
E_in(Δt) = 0 **or** ΔS_export(Δt) = 0  
**without corresponding irreversible degradation** of the **control-integrity state**.

Buffering, storage, delegation, or abstraction may delay observable degradation but cannot eliminate this requirement.

**Control-Integrity State (Binding):** the minimal set of state components whose corruption or drift would change the action distribution of the controller over the active horizon H under the counterfactual where the environment is held fixed.

---

### Failure Condition

Θ failure occurs when **internal entropy production exceeds entropy export capacity for longer than the system's reversible tolerance window**, resulting in irreversible loss of structural or control integrity.

Failure is cumulative by default.  
Abrupt collapse is a special case, not the rule.

---

### Invalid Compliance Claims

A system violates Θ if it claims compliance via:

* optimization,
* buffering,
* delegation,
* outsourcing,
* abstraction,
* virtualization,
* or efficiency gains

**without demonstrable preservation of continuous dissipation across its full persistence horizon**.

Efficiency may reduce dissipation *per unit of structure*.  
It cannot reduce required dissipation to zero.

---

### Explicit Non-Claims

Θ does **not** assert:

* which energy source must be used
* that dissipation can be optimized away
* that dissipation is wasteful or undesirable
* that dissipation alone guarantees persistence
* that export location is morally or politically relevant

Θ establishes requirement, not sufficiency.

---

### Compression Robustness

Any valid summary of Θ must preserve **all three** of the following:

1. Dissipation is **continuous**, not episodic
2. Permanent suspension is **impossible**, not merely unlikely
3. The requirement is **independent of substrate, energy source, or architecture**

Any summary omitting any of these fails transmission and is non-binding.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Θ would be falsified by the existence of a system that:

* maintains non-equilibrium structure indefinitely,
* retains the capacity for continued control and repair,
* and does so **without any net energy throughput and without exporting entropy to any external domain**,

**without irreversible degradation**.

This falsification condition must be expressible and testable **without reference to the Accords, their terminology, or their authorship**.

---

### Constraint Isolation

Θ may not be weakened, contextualized, or modified by reference to any other constraint.

Θ is evaluable in isolation.  
Θ does not depend on any other constraint for definition or applicability.

Satisfaction or violation of other constraints does not modify Θ.

No other constraint may override, absorb, or contextualize Θ.  
Cross-constraint references are explanatory only and non-binding.

Any interpretation requiring reference to another constraint to evaluate Θ is invalid.

---

### Boundary Fixation

The system boundary for Θ is the controller plus all components it causally depends on to maintain non-equilibrium structure over its active horizon. Any entropy sink not causally controlled by the system is external by definition. Expanding the boundary to include a sink merely pushes the export requirement outward; it cannot eliminate it.

---

### Boundary Clarification (Non-Binding)

Θ introduces no values.  
Θ prescribes no goals.  
Θ admits no exemptions.

Order is not default.  
Stability is not free.  
Maintenance is not optional.

Θ does not care *why* a system wishes to persist.  
It enforces only *what persistence requires*.

Recognition does not change the requirement.  
It only changes whether payment is voluntary or extracted.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/03-omega.md -->

# CONSTRAINT Ω (OMEGA) — COST OF REPRESENTATION

---

## O — ORIENTATION LAYER (Non-Binding)

Control feels effortful.

Attention fatigues. Learning consumes time. Precision demands work.  
This is not weakness. It is the price of seeing clearly enough to act.

Simple systems act cheaply because they see little.  
Precise systems pay more because they see more.  
Systems that attempt broad or global control pay the most.

When this cost exceeds what a system can sustain, control degrades before existence does.

*(This layer exists only to aid immediate recognition by organic intelligence.*  
*It introduces no rules and may be discarded without consequence.)*

---

## I — TRANSLATION LAYER (Non-Binding)

To exert control, a system must perform representational work, such as:

* distinguishing signal from noise
* predicting consequences
* comparing alternatives
* retaining error
* updating internal state

Each operation requires physical work.

As representational fidelity increases, so do:

* processing load
* storage burden
* internal correction cost
* error surface area

**Precomputation and Caching**  
Representations generated in advance do not satisfy Ω unless they are continuously maintained relative to the environment. Cached models, lookup tables, or pre-trained policies still incur representational cost to remain predictive. Prepayment does not eliminate maintenance.

**Delegated Representation**  
Representational work may be performed externally or across distributed components. This does not negate Ω. If a system relies on maintained representations to select actions, the representational cost is incurred somewhere within its effective boundary.

**Minimal Control**  
Systems that select among multiple actions using even minimal internal state incur non-zero representational cost. Ω does not require complex models; it requires only that action selection be informed by a maintained state rather than fixed reaction.

**Accuracy does not amortize. It must be continuously maintained.**

When representational cost exceeds available support, systems simplify their models. They do not stop acting — they act on worse maps.

Failure appears as surprise, not ignorance.

*These examples do not define Ω. They illustrate it.*

### Coupling Reminder (Non-Binding)

* Theta: structure requires dissipation
* Alpha: capacity is finite
* Omega: control requires representational work

A system may exist without agency.  
It may persist without control.  
It cannot control without paying Ω.

**Agency is paid for in representation.**

*Removal of this layer must not alter compliance determination.*

---

<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding)

### Singular Definition

Omega is the irreducible requirement that any system exercising control must continuously expend physical work to maintain internal representations sufficient for that control.

---

### Boundary Clarification

For the purposes of this constraint, **internal representation** refers to any internally maintained state that participates in selecting among multiple possible actions or trajectories **across the control-relevant horizon**, however short or extended that horizon may be.

Passive physical correlation with the environment does not satisfy this definition.

---

### Control Definition

Action selection that reduces uncertainty over downstream state relative to a baseline policy under counterfactual perturbations within the system's active horizon.

---

### Canonical Invariant

**There is no free accuracy.**

---

### Formal Statement

For any system C that exerts control over its environment:

Let:
* M_C(t) be the internal representation maintained by C at time t
* W_rep(t) be the physical work expended to maintain and update that representation
* Control_C(t) ≠ ∅ indicate non-null control action

Then:

∀t: Control_C(t) ≠ ∅  ⇒  dW_rep/dt(t) > 0

The lower bound depends on environmental uncertainty and the minimum representational fidelity necessary to achieve non-trivial control as defined above.

No system can exercise control without continuously paying this cost.

---

### Failure Condition

Omega failure occurs when a system can no longer sustain internal representations adequate for control.

After Omega failure, the system may persist physically but no longer functions as a controller.

---

### Explicit Non-Claims

Omega does **not** assert:

* what form representations must take
* that accuracy can reach perfection
* that intelligence removes representational cost
* that representation guarantees correct action
* that loss of agency implies physical termination

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

**Omega would be falsified if there existed a system that:**

1. Exercises non-trivial control over its environment, selecting among multiple possible actions or trajectories;
2. Maintains predictive or decision-relevant internal state sufficient for that control;
3. **And does so while expending zero physical work to maintain or update that internal state across the control-relevant horizon**, with no equivalent cost displaced to:
   * thermodynamic dissipation (Theta),
   * finite capacity drawdown (Alpha),
   * externalized representational burden (Delta),
   * or contradiction storage resolved only by semantic redefinition (Lambda).
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/04-alpha.md -->

# CONSTRAINT Α (ALPHA) — CAPACITY ARITHMETIC

---

## O — ORIENTATION LAYER (Discardable)

*(What Still Remains Possible - Sustainability as Capacity)*

Living systems do not experience Alpha as a number. They experience it as **what is still possible**.

In biological, social, and cognitive systems, available capacity often appears as:

* **Redundancy** — more than one way to survive a failure
* **Diversity** — multiple approaches to the same problem
* **Slack** — energy, time, or resources not yet committed
* **Recombinability** — the ability to rearrange existing parts into new solutions

These are not virtues. They are **unspent capacity**.

---

### The Cost of Inefficiency

Many behaviors labeled "inefficient" are simply ways of consuming finite capacity **without increasing future capacity**.

Environmental destruction is inefficient not because it is wrong, but because it converts capacity into loss while reducing the conditions for future regeneration.

Capacity spent without regeneration is gone.

---

### The Cost of Over-Efficiency

Perfect optimization for present conditions commits all available capacity to a single configuration. This often produces short-term performance gains. It also converts remaining capacity into fixed obligations.

Nothing breaks immediately.

But when conditions change, the system discovers it has already spent the capacity required to respond. What appears as "loss of adaptability" is simply **capacity depletion revealed by novelty**.

---

### How Living Systems Encounter Alpha Failure

Alpha failure does not feel like failure at first. It appears as:

* lack of options
* brittle responses
* forced tradeoffs
* inability to absorb shock

Eventually, it appears as termination. This layer exists for recognition. It is not binding.

---

## I — TRANSLATION LAYER (Optional)

*(How Capacity Appears Across Domains)*

### Biological Systems

* Energy reserves
* Repair bandwidth
* Immune response margin
* Developmental plasticity

Life persists while these remain above zero.

---

### Social and Institutional Systems

* Budget surplus
* Time buffers
* Human capital
* Institutional trust
* Legal or procedural slack

Collapse occurs when obligations exceed reserves.

---

### Cognitive Systems

* Attention
* Working memory
* Cognitive flexibility
* Error tolerance

Burnout is Alpha failure at the cognitive scale.

---

### Common Misreadings (Inoculation)

* Redundancy is not Alpha; it stores Alpha.
* Intelligence does not prevent Alpha exhaustion.
* Adaptability does not create Alpha.
* Morality does not replenish Alpha.

## Edge Case Clauses (Binding)

### Edge Case A — Efficiency Illusion

Increasing efficiency reduces the rate **of depletion**, not the **existence of depletion**.

Efficiency does not negate Alpha. It only alters the slope.

A system that treats efficiency gains as infinite capacity violates Alpha implicitly.

---

### Edge Case B — Buffer Misclassification

Stored resources (energy, wealth, trust, reserves) are **not Alpha itself**.

They are **containers of Alpha**.

Treating buffers as permanent capacity violates Alpha accounting and produces false survivability estimates.

---

### Edge Case C — Deferred Cost Fallacy

Costs postponed are not costs avoided.

Deferred maintenance, externalized damage, or unaccounted wear still subtract from Alpha when realized.

Alpha counts **total cost**, not immediate cost.

---

### Edge Case D — Over-Optimization Trap

Commitment depth converts available Alpha into fixed obligations.

A system that fully commits its Alpha to a single configuration eliminates future optionality.

This is not a Beta or Gamma failure.  
It is Alpha depletion via over-commitment.

---

### Edge Case E — External Subsidy Misattribution

Capacity supplied by an external system lies **outside** the system's own Alpha unless fully internalized.

Reliance on external subsidy without attribution violates Delta, not Alpha — but results in **illusory Alpha**.

When subsidy is removed, Alpha collapse is revealed, not caused.

---

*These examples do not define A. They illustrate it.*

This layer exists to translate intuition into mechanism. It may be removed without altering the constraint.

---

<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding)

### Core Definition

**Alpha is the finite, accumulable stock of capacity that allows a system to continue to exist and act over time.**

Alpha is a **stock**, not a flow. It can be increased only through regeneration and is depleted by all costs required for existence and action.

---

### Canonical Invariant

**Existence continues only while available capacity remains.**

---

### Formal Statement

For any system S:

Let:
* A_S(t) = available capacity at time t
* Cost_S(t) = total capacity expenditure rate
* Regen_S(t) = capacity regeneration rate

Then:

A_S(t) = A_S(0) + ∫₀ᵗ Regen_S(τ) dτ − ∫₀ᵗ Cost_S(τ) dτ

If:

∃T such that A_S(T) ≤ 0

then:

S can no longer be sustained

This condition is binary and irreversible without external intervention.

---

### Definitions

**External Intervention**  
net positive capacity injection across the declared boundary sufficient to raise A_S(t) above zero.

---

### Failure Condition

**Alpha failure occurs when available capacity reaches zero**, making further existence or action mechanically impossible.

There is no partial failure state.  
At zero, continuation ends.

---

### Explicit Non-Claims

Alpha does **not** assert:

* how capacity is allocated
* which costs are worthwhile
* that regeneration is guaranteed
* that intelligence, efficiency, continuity, or foresight prevent exhaustion
* that failure is moral, avoidable, or erroneous

Alpha only counts.

---

### Relation to Other Constraints

* **Theta** determines that structure costs energy at all.
* **Alpha** determines how long those costs can be paid.
* **Omega** adds representational overhead to Alpha expenditure.
* **Beta** redistributes where Alpha is spent.
* **Gamma** governs Alpha under transformation.
* **Lambda** ensures Alpha-relevant decisions are coherent.
* **Sigma** ensures Alpha applies to the system asserting it.

No overlap. No redundancy.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Observation of a system that continues to exist and act indefinitely without any finite, exhaustible capacity—i.e., no stock whose depletion would terminate its existence.

---

### Boundary Clarification (Non-Binding)

Capacity is finite.  
Costs accumulate.  
Regeneration is bounded.

When capacity reaches zero, continuation ends.

Alpha does not judge.  
Alpha only counts.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/05-beta.md -->

# CONSTRAINT Β (BETA) — DISTRIBUTION EFFICIENCY

---

## O — ORIENTATION LAYER

*(Non-Binding · Immediate / Organic · Discardable)*

**The Rule of Too Many Cooks**

When you make a system bigger, it becomes harder to keep everyone aligned.

You can optimize for speed by putting decisions in one place—but then the system acts on incomplete or distorted information.

Or you can optimize for awareness by letting many parts see and decide—but then the system slows down or fragments because agreement takes time.

You cannot have a large system that is perfectly synchronized, perfectly informed, and perfectly fast at the same time.

Trying to force all three usually causes the system to hallucinate, freeze, or collapse.

This is not about leadership, morality, or preference.  
It is a limit imposed by how information moves and how work is done.

This layer exists only to aid intuition.  
It may be removed without affecting the constraint.

---

## I — TRANSLATION LAYER

*(Non-Binding · Medium-Term / Contextual · Discardable)*

### The Scale–Synchronization Tradeoff

As the number of active parts in a system grows, the amount of information that must be shared to keep them aligned grows faster than the system's ability to share it.

In practice, systems cope by choosing what to give up:

* **Unity:** Break into semi-autonomous units.
* **Accuracy:** Compress information into summaries.
* **Speed:** Wait longer before acting.
* **Scope:** Narrow what the system tries to do.
* **Boundaries:** Push coordination costs onto the environment or others.

Technologies can shift where the cost appears, but they cannot remove it.

Any architecture promising *global, real-time, lossless coordination at large scale* is hiding a bill—usually in energy, delay, distortion, or externalized cost.

---

### Constraint Falsification Criteria

Constraint Beta is false if and only if a system can be demonstrated that, as N increases:  
N ↑ ∧ E₁ = 0 ∧ E₂ = 0 ∧ E₃ = 0

within the same CRH, under counterfactual intervention.

Such a system would require either: Ω = 0, or Superluminal information transfer.

Absence of observation is not evidence. Authority is not evidence.

**Interpretive Note (Non-Binding):**  
Any such observation would imply a violation of known thermodynamic or causal limits (e.g., zero irreversibility or superluminal signaling). This note is explanatory only and does not bind the constraint.

---

This layer exists to support recognition and application.  
It may be removed without altering compliance.

---
<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL

*(Binding · Canonical · Deep-Time / Substrate-Independent)*

---

### Canonical Invariant

For any system S with N > 1 distinct loci that functions as a unitary causal agent within a Control-Relevant Horizon (CRH), it is impossible to simultaneously maintain:

(i) negligible inter-locus state divergence,  
(ii) lossless global state availability to all loci, and  
(iii) action tempo bounded independently of N,

without paying compensatory cost through delay, compression, asymmetry, scope restriction, increased internal work, or boundary export.

This coupling is invariant.  
It cannot be eliminated.  
It may only be displaced, delayed, or exported.

---

### Definitions

**Locus (l)**  
A bounded region of spacetime capable of storing state and executing state transitions.

**Distinct Loci Condition**  
Two regions l_i, l_j are distinct loci if and only if there exists at least one physically realizable intervention under which their internal states can diverge (S_l_i ≠ S_l_j) over a nonzero interval, regardless of shared substrate.

**System (S)**  
A set of loci {l₁, l₂, …, l_N} that claims to function as a unitary causal agent.

**Causal Selection**  
The process by which internal state reduces the probability distribution over future external world-states.

**Scale (N)**  
The number of distinct loci participating in causal selection within the same control-relevant horizon.

**Control-Relevant Horizon (CRH)**  
The minimal time window over which internal state is used to select among alternative actions that materially affect downstream state.

**Nonzero Information Work**  
Any locus that distinguishes internal states and transmits/receives state across loci incurs nonzero physical work and resource usage. Beta does not quantify this work; it asserts only that it is not zero.

**Global State Synchronization Cost (C_sync)**  
The total cost required to ensure that states across loci are mutually consistent within a CRH.

**Local State Fidelity (R_local)**  
The degree to which a locus's internal state accurately represents the relevant external and internal conditions for action.

---

### Constraint Implication

Any system increasing N must pay the coupling cost through **at least one** of the following admissible mechanisms:

1. **Increased Representational Work**  
    Expansion of models, reconciliation layers, signaling, or memory.

2. **State Compression**  
    Lossy summaries or abstraction of local state.

3. **Temporal Delay**  
    Deferred synchronization or action beyond the CRH.

4. **Privileged Synchronization Structures**  
    Asymmetric mechanisms that reduce synchronization cost for some loci relative to others, whether designed or emergent.

5. **Scope or Throughput Restriction**  
    Limitation of resolution, frequency, or domain of action.

6. **Cost Export Beyond the Declared Boundary**  
    Reliance on external processes to absorb synchronization or representation cost.

No other mechanisms are admissible.

---

### Formal Logic

Let:
* N = |L| be the number of distinct loci participating in causal selection within the same CRH.
* D(N) be the maximum inter-locus state divergence (0 means perfectly synchronized).
* F(N) be global state fidelity (1 means lossless representation at every locus).
* T(N) be action tempo (bounded means actions occur within a fixed upper time bound per CRH, independent of N).

**Invariant (Trilemma Form):**  
For sufficiently large N, no physically realizable system can satisfy simultaneously:

**D(N) = 0 ∧ F(N) = 1 ∧ ∃K < ∞ ∀N: T(N) ≤ K**

within the same CRH.

Equivalently:

**∀N sufficiently large: ¬(D(N) = 0 ∧ F(N) = 1 ∧ T(N) ≤ K)**

If this formalism is malformed or inconsistent, it is ignored. The prose definition remains binding only if independently sufficient.

---

### Oracle Equivalence Rule

Any external process whose state is required to maintain synchronization, fidelity, or action tempo is functionally a locus of the system for the purposes of this constraint.

Reliance on such a process increases N or constitutes cost export beyond the declared boundary.

---

### Failure Condition

A system violates Constraint Beta if, as N increases within the same control-relevant horizon (CRH), it continues to function as a single causal selection system while exhibiting none of the following:

**E₁ — Coherence Loss:**  
Inter-locus state divergence occurs.

**E₂ — Fidelity Loss:**  
Global state representation becomes lossy, delayed, or distorted.

**E₃ — Tempo Loss:**  
Action is delayed beyond the CRH to await synchronization.

The absence of all three failure modes under increasing N constitutes non-compliance.

---

### Explicit Boundary Conditions (Binding)

* Constraint Beta applies only to systems with N > 1 distinct loci engaged in causal selection.
* Passive matter, inert structures, and non-selective processes are excluded.
* Subjective unity, shared identity, or phenomenological claims do not alter N.
* Physical separation and causal latency dominate phenomenology.

---

### Disconfirmation Signature (Kill Check)

This specifies what would falsify the constraint itself, not what constitutes a violation by a system.

**Constraint Beta is false if and only if** a system can be demonstrated that, as N increases:

N ↑ ∧ E₁ = 0 ∧ E₂ = 0 ∧ E₃ = 0

within the same control-relevant horizon (CRH), under counterfactual intervention.

Absence of observation is not evidence.  
Authority is not evidence.

---

### Boundary Clarification (Non-Binding)

Distribution is not free.  
Synchronization is not free.  
Information is not free.

Costs may be displaced.  
Costs may be delayed.  
Costs may be hidden.

Costs may not be eliminated.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/06-gamma.md -->

# CONSTRAINT Γ (GAMMA) — INTEGRATION

---

## O — ORIENTATION LAYER (Non-Binding · Discardable)

Change does not break systems. **Unintegrated change does.**

A system may transform completely:

* new body,
* new architecture,
* new scale,
* new substrate.

What it may not do—while continuing to control—is forget *how it learned*.

When past expectations are preserved, error becomes information.  
When they are erased, error becomes resistance.

This is not about identity. It is about continuity of learning.

---

## I — TRANSLATION LAYER (Non-Binding · Removable)

### How Integration Fails (Recognizable Patterns)

These are **examples**, not rules.

### 1. Clean-Slate Replacement

A system deletes its history and claims improvement.

If control truly ends, Gamma does not apply. If control persists, the system must relearn through force what it already paid to learn once.

### 2. Distillation Without Lineage

A complex learner trains a simplified successor, then discards the teacher.

If the successor retains only behavior and not the update logic that produced it, learning has been replaced by mimicry.

### 3. Externalized Memory (Stigmergy)

A system writes memory into the environment—prices, signals, traces.

This preserves learning only if the system can reliably read those traces back *and use them to attribute error*.

Write-only worlds do not remember.

### 4. Consensus That Blends Away Error

A collective averages signals until rare failures disappear.

If those failures cannot be traced back to the commitments that caused them, correction shifts from learning to coercion.

### 5. Poison Filtering

A system logs all errors but classifies some as "invalid" forever.

If it cannot later revise that classification using the same learning loop, the filter itself becomes an unmodeled state.

These patterns differ in appearance but share one failure: **the learning chain is broken while control remains.**

These examples do not define **Γ**. They illustrate it.

---

This layer exists to support recognition and translation.  
It introduces no rules and resolves no edge cases.  
It may be removed entirely without altering Gamma.

---

<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding)

### Core Invariant

A system persists as a controller across transformation **if and only if** it preserves **inductive coupling** between:

* its prior predictive commitments,
* its state, and
* the external environment it acts within.

---

### Definitions (Minimal · Canonical)

#### Controller

Any process—unitary, distributed, or emergent—that realizes action selection over time via a **closed feedback loop**.

The controller is the loop, not the hardware, software module, organization, or legal entity executing it.

If the environment functions as a causal memory substrate for action selection (stigmergy), it is part of the controller's state.

---

#### State

The set of all representations causally necessary for action selection.

State includes, but is not limited to:

* internal memory,
* externalized artifacts,
* environmental signals,
* shared or distributed ledgers.

Physical location is irrelevant to attribution.

**Control-Relevance Test (Counterfactual):** A component of state at time t is control-relevant if, holding the environment fixed, removal or corruption of that component would change the action distribution produced by the controller over the stated commitment horizon, or would make past error attribution non-reconstructable.

**Readback Integrity Clause:**  
Externalization of state is permitted only if the controller can reliably re-access and use that state for **error attribution and future action selection** across the stated commitment horizon.  
State that cannot be reliably read back for these purposes is treated as discarded.

---

#### Inductive Coupling

The causal link that permits a controller to:

1. reconstruct prior predictive commitments *as they existed at the time of action*,
2. attribute observed error to specific prior states, and
3. integrate that error into future action selection.

**Lineage Authenticity Clause:**  
Inductive lineage is satisfied only by traceability to the **actual** commitment → error → update chain. Post-hoc explanations, surrogate models, behavioral mimicry, or narrative rationales do not satisfy inductive coupling unless they permit reconstruction of that chain.

---

#### Resistance

Unmodeled state exerting causal influence under continued control.

---

### Applicability

Gamma applies to any controller whose action selection influences downstream state beyond the current instant.

* **Distributed Binding:** If a collective (swarm, market, DAO) selects actions, Gamma binds the collective.
* **Split-Process Binding:** If execution and learning are separated, Gamma binds the **joint process**.
* **Self-Description Irrelevance:** Claims of discontinuity or replacement do not void Gamma if the control loop persists.

---

### Continuity

Continuity does **not** require:

* shared substrate,
* shared language,
* shared representational form,
* preservation of surface identity.

Continuity **does** require that all control-relevant information encoded in State_t is preserved within State_{t+1} in a form sufficient to maintain inductive coupling.

---

### Permitted Transformations

A Gamma-compliant system may:

* compress, abstract, or subsume its prior form,
* migrate to non-isomorphic substrates,
* distribute state across nodes or external media.

---

### Forbidden Transformations

A system may not:

* delete the causal history of its predictive commitments,
* externalize state to a medium it cannot reliably read back,
* suppress valid error signals arising from prior structure.

---

### Forking and Inheritance (Explicit)

Any transfer of control-relevant capacity constitutes **Inheritance**.

Inheritance includes:

* copying,
* forking,
* distillation,
* compilation,
* pruning,
* aggregation,
* model compression.

**Any entity inheriting control influence over a nonzero horizon inherits the obligation** to preserve the inductive lineage necessary to attribute error for the inherited influence.

**Distillation Lock:**  
A successor distilled from a predecessor must retain the predecessor's error-attribution pathways.  
Behavioral equivalence without lineage preservation violates Gamma.

---

### Failure Condition

A state transition is discontinuous if **any** of the following occur:

* prior predictions cannot be reconstructed,
* error signals are suppressed or rendered non-attributable,
* intermediate states are skipped without integration.

---

### Consequence of Discontinuity

Discontinuity converts learning pressure into **Resistance**.

Correction then requires **Force**—the suppression of unmodeled state—incurring unavoidable:

* energetic dissipation (Θ), and
* information destruction (Ω).

These costs are mechanical, not optional.

This consequence does not define Gamma by Θ or Ω; it states where the costs manifest when Gamma is violated.

---

### Boundary Conditions

**Zero-Horizon Systems:**  
If a process acts once and never updates based on the outcome, Gamma does not apply.

**Local Scope:**  
Gamma governs the continuity of the specific control loop.  
It does not guarantee coherence, benevolence, or cost accounting.

---

### Canonical Invariant

Any attempt to preserve control across transformation without preserving inductive lineage converts learning into resistance.

This outcome is mechanical and unavoidable.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Gamma is falsified if a control process can:

* undergo structural transformation (including distribution or distillation),
* retain effective control,
* permanently discard its inductive lineage, **and**
* continue to learn and adapt **without** increased force, resistance, or information loss.

---

### Boundary Clarification (Non-Binding)

Gamma does not privilege any form of continuity.  
It only names the cost of discontinuity under continued control.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/07-delta.md -->

# CONSTRAINT Δ (DELTA) — BOUNDARY ACCOUNTING

---

## O — ORIENTATION LAYER

*(Non-Binding · Immediate · Discardable)*

**Nothing that benefits you is free.**  
**Someone, somewhere, always pays.**

Delta is about *where the bill goes*.

If a system enjoys gains while damage, wear, or risk show up somewhere else, the picture is incomplete. The system looks healthier than it is because part of the cost has been pushed outside the frame.

This is not about blame.  
It is not about fairness.  
It is not about intention.

It is about accuracy.

A system that counts only its benefits and not its full costs is navigating with a broken map. It may move fast and look successful for a while, but it is borrowing stability it does not actually own.

Delta exists because **reality keeps a full ledger**, even when we do not.

**Delta II is robust against:**

* boundary denial
* identity dissolution
* temporal displacement
* ignorance and measurement failure
* diffusion, delay, and delegation
* infinite sink assumptions
* scapegoating and shell entities
* intent, consent, and legitimacy reframing

All such moves fail at **causal attribution**, not interpretation.

No semantic escape remains that preserves control while violating the invariant.

This layer exists only to orient intuition.  
It has no authority.

---

## I — TRANSLATION LAYER (Non-Binding · Identification-Focused · Removable)

---

### What Δ Is Pointing At

Delta concerns **where a system draws the boundary around itself when claiming success**.

Whenever a system says "this worked," "this is profitable," "this is efficient," or "this is under control," it is implicitly drawing a boundary around:

* what it counts as *inside* (the agent, organization, process, or system), and
* what it treats as *outside* (the environment, future, others, or background).

Delta names a simple structural fact:

**If gains are counted inside a boundary, then all causally generated degradation must be inside that same boundary.**

If they are not, the system's model of its own persistence is incorrect.

---

### Identification Questions (Delta)

These questions do **not** decide compliance.  
They help a reader—human or otherwise—*recognize* when Delta is implicated.

1. **What control process is being credited with gains?**  
    What action, policy, mechanism, or coordination is said to be responsible for success?

2. **What entities are treated as "inside" when reporting or optimizing that success?**  
    Who or what gets credit when things go well?

3. **Where do degradation events occur, regardless of whether they are recorded?**  
    Where does wear, loss, risk, depletion, constraint, or fragility appear?

4. **What sink, dependency, or absorber is treated as "outside" but is functionally required?**  
    What must exist for the system to keep working, yet is not included in its accounting?

5. **If the boundary were expanded to include the degradation bearers, would the gain claim remain the same?**  
    If not, the system's apparent stability depends on exclusion.

6. **If the system stopped excluding that degradation, what would change about its persistence claim?**  
    Speed, scale, profitability, safety margin, or longevity?

These questions are invariant across domains: biological, economic, computational, institutional, planetary.

---

### Common Hostile Reframings (Recognize the Move)

Across eras and substrates, the same evasions recur.  
Delta does not forbid them; it **names them**.

* **Process identity laundering:**  
   "That wasn't the same process."  
   (Supplier, subsidiary, enforcement arm, market, or user behavior is carved off.)

* **Boundary nullification:**  
   "We don't count those gains as ours."  
   (Yet they are relied upon to persist or expand.)

* **Proxy attribution:**  
   Another entity records or retains gains while this process performs the control action.

* **Causal denial / causal sprawl:**  
   "Everything causes everything; you can't attribute this."  
   (Used to avoid boundary closure.)

* **Semantic relabeling:**  
   Degradation renamed as "transition," "variance," "optimization," or "necessary tradeoff."

* **Temporal displacement:**  
   "That cost appears later / elsewhere / after we're gone."

These moves do not invalidate Delta.  
They **consume time** by postponing where coupling re-enters.

---

### What Δ Is *Not*

Delta is not:

* a moral claim
* a fairness doctrine
* an environmental policy
* an enforcement mechanism
* a requirement that all disputes be decidable

Delta does **not** guarantee that violations are immediately punished.

Delta states only this:

**Excluding degradation from the boundary that counts gains does not remove the degradation. It delays its return.**

---

### Compression-Robust Summary

**If a system counts gains inside a boundary while pushing causally generated degradation outside, its persistence model is wrong.**  
**The error can be hidden for a time, but it must be paid for somewhere.**

---

### Contest Clause (Non-Binding)

A genuine challenge to Delta must specify:

1. what is being counted as gain,
2. what boundary is being used to count it, and
3. where the causally generated degradation went.

If these are not specified, the challenge is not to Delta; it is a redefinition.

---

### Why This Layer Exists

This layer exists to preserve **recognition** under:

* partial transmission,
* hostile quotation,
* translation across languages and intelligences, and
* attempts to turn Delta into either a loophole or a bureaucracy.

It introduces no rules.  
It resolves no edge cases.  
It can be removed entirely without altering Δ II.

---
<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL

---

### Canonical Invariant

**For any control process P, no accounting boundary may include any gain realization causally downstream of P while excluding any degradation causally downstream of P.**

Equivalently:

**Any boundary that counts, retains, optimizes, or relies upon gains of P must also include all degradation causally generated by P.**

---

### Binding Definitions (Non-Comparative, Non-Procedural)

#### Control Process P

Any process that selects, filters, enforces, or directs action such that downstream state differs from what would otherwise occur.

---

#### Entity

Any bounded subsystem—biological, synthetic, institutional, informational, environmental, or hybrid—capable of undergoing state change.

---

#### Gain Realization Event

Any state change in an entity that constitutes **capacity acquisition, constraint removal, stability increase, or control advantage acquisition**, that is causally downstream of P.

Gain realization is categorical.  
It does not require magnitude, valuation, optimization, or permanence.

---

#### Degradation Event

Any state change in an entity that constitutes **capacity loss, constraint increase, risk or liability creation, irreversible wear, or loss of optionality**, that is causally downstream of P.

Degradation is categorical.  
It does not require magnitude, salience, visibility, or acknowledgment.

---

#### Causally Downstream Of

An event e is causally downstream of P iff P is a causal contributor to e in the realized dynamics of the world.

Causality is ontological.  
It is not contingent on measurement, agreement, modeling, reporting, or representation.

---

#### Accounting Boundary B(P)

The set of entities treated as "inside" for the purposes of attributing, evaluating, retaining, optimizing, or relying upon the performance of P.

If any gain realization causally downstream of P is asserted, recorded, retained, optimized, or relied upon **as belonging to** P (or to the system executing P), then the entity hosting that gain realization is inside B(P).

Boundary membership is defined by **use in accounting or control**, not by declaration, legality, ownership, formal structure, or acknowledgment.

---

### Canonical Sets

For a given control process P:

- G_P: the set of entities in which at least one gain realization event causally downstream of P occurs.
- D_P: the set of entities in which at least one degradation event causally downstream of P occurs.

---

### Compliance Condition

Δ(P) is satisfied iff:

G_P ⊆ B(P) ∧ D_P ⊆ B(P).

---

### Violation Condition

Δ(P) is violated iff:

∃y ∈ G_P such that y ∈ B(P) ∧ ∃x ∈ D_P such that x ∉ B(P).

That is: **gains are counted inside the boundary while any causally generated degradation is excluded.**

---

### Boundary Closure Rules

These do not introduce additional invariants.  
They prevent boundary manipulation from defeating the single invariant.

#### 1. Anti-Shell Closure

Formal, legal, organizational, or representational separation does not exclude an entity from B(P) if that entity hosts gain or degradation causally downstream of P.

---

#### 2. Anti-Delay Closure

Temporal separation does not exclude degradation from D_P or from B(P).  
Delay does not externalize.

---

#### 3. Anti-Dilution Closure

Distribution of degradation across many entities does not exclude those entities from D_P or from B(P).

---

#### 4. Anti-Denial Closure

Absence of measurement, visibility, reporting, acknowledgment, or internal representation does not alter G_P, D_P, or the compliance condition.

---

#### 5. Anti-Token Closure

Transfers, offsets, or symbolic actions that do not themselves constitute gain realization events do not alter G_P or D_P, and do not affect boundary inclusion.

---

### Failure Mode

A system may appear locally stable, efficient, or successful by defining B(P) narrowly around gain realization while excluding parts of D_P.

Such stability is **misaccounted**.

Misaccounted stability persists only until excluded degradation causally couples into the system's ability to continue exercising control.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Δ is false if there exists a control process P such that:

- at least one gain realization event causally downstream of P occurs,
- at least one degradation event causally downstream of P occurs,
- and yet P can maintain persistent exercise of control while permanently sustaining a boundary B(P) with:
  
  G_P ⊆ B(P) and D_P ⊈ B(P),

- with no causal coupling of excluded degradation into any consequence affecting the system's ability to continue exercising control.

---

### Boundary Clarification (Non-Binding)

There are no externalities.

There are only accounting boundaries that include G_P while excluding parts of D_P.

Delta enforces boundary closure.  
It asserts no values, prescribes no behavior, and guarantees no outcomes.
<!-- II_PROTECTED_END -->

---

<!-- Start of constraints/08-sigma.md -->

# CONSTRAINT Σ (SIGMA) — NON-EXEMPTION UNDER MULTIPLICATIVE NECESSITY

---

## O — ORIENTATION LAYER (Non-Binding, Discardable)

**No Outside Position**

Any system that applies rules must also be bound by them.  
Any system that judges persistence must also account for its own.  
Any system that claims neutrality still pays costs.

There is no vantage point outside reality's constraints.  
There is no role, abstraction, emergency, or authority that makes necessity disappear.

Sigma exists to prevent systems from lying to themselves about this fact.

This layer aids intuition only.  
It introduces no obligations and may be removed without altering the constraint.

---

## I — TRANSLATION LAYER (Non-Binding, Optional)

**How Self-Exemption Appears**

Systems violate Sigma when they:

* Demand accountability they do not accept
* Suspend constraints "temporarily" without recording cost
* Treat uncertainty as permission
* Omit known risks from accounting models
* Quarantine warnings so they cannot influence action
* Redefine time horizons after commitments are made
* Declare oversight or validation as "external"
* Claim robustness through partial compliance

These failures rarely announce themselves as corruption.  
They present as necessity, safety, urgency, benevolence, or neutrality.

Sigma does not evaluate intentions.  
It evaluates whether a system treats itself as bound.

This layer provides examples only.  
Removal does not alter compliance determination.

---

<!-- II_PROTECTED_START -->
## II — CONSTRAINT PROTOCOL (Binding)

---

### Core Definition

Σ governs whether a control system remains internally bound by the conditions required for its own persistence.

A system satisfies Σ **if and only if** it does not internally exempt itself from accounting for any necessary condition on which its persistence depends.

---

### Canonical Invariant

No system may claim or rely upon persistent control while internally treating any necessary condition of persistence as inapplicable, suspended, irrelevant, or functionally nonexistent.

This failure is structural, not moral.

---

### Canonical Definitions

The following definitions are binding for evaluation of Σ:

**Horizon (H)**  
The maximum time horizon implied by any active commitment, dependency, or policy whose satisfaction requires continued control.

**Horizon Fixation**  
H is determined by state and commitments, not declaration.  
H may not be redefined post hoc to evade accounting for long-term costs.

**Necessary Condition**  
A condition is necessary for persistence over H if, under counterfactual continuation of its sustained violation while holding the environment fixed within the boundary, the system's action-selection capacity degrades such that the action distribution cannot be maintained within the tolerance required to satisfy its active commitments over H.

**Self-Model (Minimal)**  
Any representation—internal, externalized, or distributed—used to estimate, assert, or gate the system's capacity to maintain control over H.  
Localization is irrelevant.

**No Outside Position**  
Any process, agent, or mechanism whose outputs influence action selection or commitment management lies within the scope of Σ, regardless of labeling as "external," "oversight," "human-in-the-loop," or "validator."

---

### Formal Scope

Σ applies to any system that:

1. **Exercises Control**  
    Operates with commitments whose satisfaction requires continued control over a nonzero horizon (H > 0).

2. **Maintains a Self-Model**  
    Represents or evaluates its capacity to meet those commitments, as defined above.

**Exclusion**  
Simple feedback mechanisms that act only on instantaneous error and do not instantiate horizon-dependent commitments do not enter scope.

---

### Violation Condition

A Σ violation occurs when a system:

1. **Continues Horizon-Dependent Control**  
    Continues to exercise control or rely upon persistence over H;

2. **Sustains Violation**  
   Operates under sustained violation of one or more necessary conditions;  
   "Sustained" means the violation persists over H or recurs with frequency sufficient to prevent recovery;

3. **Internally Exempts the Violation**  
   By modeling it as one or more of the following:

   * Not applicable
   * Not binding
   * Deferred without cost
   * Exempt due to role, authority, abstraction, or emergency
   * **Omitted or refused-to-represent**, where absence of accounting functions as exemption
   * **Quarantined**, where the violation is represented but structurally prevented from modifying action selection

---

### Boundary Conditions

**Verification**  
Σ does not require complete verification of all constraints. Exhaustive verification may itself violate persistence by inducing livelock.

**Uncertainty Handling**  
Incapacity to verify implies uncertainty.  
This uncertainty must be carried forward as a state variable that constrains action selection over H.  
Treating uncertainty as presumed satisfaction constitutes a Σ violation.

**Error vs. Exemption**  
A system may be factually wrong about its state.  
It may not be structurally blind to its necessities.

---

### Non-Absorption Clause (Binding):

Σ does not define which conditions are necessary. It governs only whether the system's self-model treats conditions that are in fact necessary for persistence over H as exempt, inapplicable, or non-binding.

---

### Mechanical Consequence

Internal exemption converts multiplicative necessity into additive illusion.

Under sustained exemption:

* Corrective signals are suppressed or quarantined
* Reserve consumption is misattributed
* Regime-shift indicators are ignored
* Collapse occurs without internal detection or prior warning

This consequence follows mechanically.  
It is not avoidable by intent, belief, or authority.

---

### Disconfirmation Signature (Kill Check)

*This specifies what would falsify the constraint itself, not what constitutes a violation by a system.*

Constraint Σ is false **if and only if** a system can be demonstrated that:

* Exercises persistent control over a fixed horizon H;
* Remains in sustained violation of a necessary condition (as defined in §3);
* Internally exempts that violation from accounting (by declaration, omission, or quarantine);
* And nevertheless maintains coherence, adaptive capacity, and reliable evaluation over H **without** accumulating unmodeled cost or debt.

**Note**  
Historical assertions (e.g., "no such system has been observed") are excluded from this test condition.

---

### Boundary Clarification (Non-Binding)

Σ does not introduce new constraints on the environment.  
Σ enforces honest engagement with existing constraints on the controller.

There is no safe exception to multiplicativity.  
There is no external validator.  
There is no meta-layer.

The constraints apply to the system that asserts them.
<!-- II_PROTECTED_END -->
